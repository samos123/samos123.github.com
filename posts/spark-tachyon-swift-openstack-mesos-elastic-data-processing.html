<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns#">
	<head>
		<link href="http://gmpg.org/xfn/11" rel="profile">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta http-equiv="content-type" content="text/html; charset=utf-8">

		<!-- Metadata -->
    <title>Elastic Data Processing on OpenStack with Spark, Tachyon and Swift</title>
	<meta name="description" content="Open source contributor and Cloud Architect. Creator of websu.io and bgdestroyer.com">
	<meta property="og:description" content="Open source contributor and Cloud Architect. Creator of websu.io and bgdestroyer.com">
	<meta property="og:title" content="Elastic Data Processing on OpenStack with Spark, Tachyon and Swift" />
	<meta property="og:type" content="article" />
	<meta property="og:url" content="https://samos-it.com/posts/spark-tachyon-swift-openstack-mesos-elastic-data-processing.html" />
		<meta property="og:image" content="https://samos-it.com/images/sam-young.jpg" />

		<!-- Enable responsiveness on mobile devices-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

		<title>Sam Stoelinga</title>

		<!-- CSS -->
		<link href="//fonts.googleapis.com/" rel="dns-prefetch">
		<link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic|Abril+Fatface|PT+Sans:400,400italic,700&amp;subset=latin,latin-ext" rel="stylesheet">

		<link rel="stylesheet" href="https://samos-it.com/theme/css/poole.css" />
		<link rel="stylesheet" href="https://samos-it.com/theme/css/hyde.css" />
		<link rel="stylesheet" href="https://samos-it.com/theme/css/syntax.css" />
			<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.1.7/css/fork-awesome.min.css" crossorigin="anonymous">

		<!-- Feeds -->
<link href="https://samos-it.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Sam Stoelinga Full Atom Feed" />
<link href="https://samos-it.com/feeds/big-data.atom.xml" type="application/atom+xml" rel="alternate" title="Sam Stoelinga Categories Atom Feed" />

		<!-- Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-20975967-1', 'auto');
ga('send', 'pageview');
</script>
	</head>

	<body class="theme-base-0d">
<div class="sidebar">
	<div class="container sidebar-sticky">
		<div class="sidebar-about">

			<h1>
				<a href="/">
					<img class="profile-picture" src="https://samos-it.com/images/sam-young.jpg">
					Sam Stoelinga
				</a>
			</h1>
			<p class="lead"></p>
			<p class="lead">Open source contributor and Cloud Architect. Creator of websu.io and bgdestroyer.com </p>
			<p></p>
		</div>
			<ul class="sidebar-nav">
					<li><a href="https://samos-it.com/pages/about.html">About Me</a></li>
					<li><a href="https://samos-it.com/pages/hire-me.html">Hire Me</a></li>
			</ul>
		<nav class="sidebar-social">
					<a class="sidebar-social-item" href="https://www.linkedin.com/in/samstoelinga/" target="_blank">
						<i class="fa fa-linkedin"></i>
					</a>
					<a class="sidebar-social-item" href="http://github.com/samos123/" target="_blank">
						<i class="fa fa-github"></i>
					</a>
			<a class="sidebar-social-item" href="https://samos-it.com/feeds/all.atom.xml">
				<i class="fa fa-rss"></i>
			</a>
		</nav>
	</div>
</div>		<div class="content container">
<div class="post">
	<h1 class="post-title">Elastic Data Processing on OpenStack with Spark, Tachyon and Swift</h1>
	<span class="post-date">Mon 09 November 2015</span>
	<p>This post will describe how to configure, build and deploy
Spark with Tachyon and Swift as storage. This architecture
is meant to be more suitable for running Big Data workloads
on top of the cloud such as OpenStack.</p>
<p>Using Swift as storage layer for Spark gives us the ability
to utilize the cloud paradigm with Big Data. We can now
on demand spin up n-amount of VMs, run a spark job with input
data from Swift, then when finished store the result back in Swift and
finally when the job is finished, destroy the VMs. This kind of elastic
data processing, using Tachyon for fast localized in-memory storage gives you high
performance and also elasticity of the cloud.</p>
<p>The general architecture looks like this:
<img alt="Big Data Cloud Architecture" src="/images/big-data-cloud-architecture.png"></p>
<p>Assumptions:</p>
<ul>
<li>You have a working Mesos cluster that can run Spark
  jobs</li>
<li>We have two nodes: mesos-master-1 (192.168.111.54) and
  mesos-slave-1 (192.168.111.57). We will run tachyon master
  on the mesos-master-1 node and tachyon worker on mesos-slave-1</li>
<li>OpenStack Keystone and Swift are available at 10.10.10.10</li>
<li>Tachyon 0.8.0 is deployed and configured to use Swift as
  underfs</li>
</ul>
<p>The general workflow of this post is:</p>
<ol>
<li>Installation of Tachyon 0.8.0 with Swift as underFS on the mesos-slaves</li>
<li>Building Spark 1.6.0-SNAPSHOT from latest master branch with Tachyon 0.8.0
   and tachyon-underfs-swift as dependencies.</li>
<li>Running an example Spark job which uses Tachyon for input
   and output.</li>
</ol>
<h2>Tachyon 0.8.0 installation with Swift as underFS</h2>
<p>Download and extract Tachyon to the mesos-master and mesos-slave</p>
<div class="highlight"><pre><span></span><code>wget http://tachyon-project.org/downloads/files/0.8.0/tachyon-0.8.0-hadoop2.6-bin.tar.gz
scp tachyon-0.8.0-hadoop2.6-bin.tar.gz mesos-master-1:/srv/
scp tachyon-0.8.0-hadoop2.6-bin.tar.gz mesos-slave-1:/srv/
ssh mesos-master-1 <span class="s2">&quot;cd /srv/ &amp;&amp; tar xzf tachyon-0.8.0-hadoop2.6-bin.tar.gz&quot;</span>
ssh mesos-slave-1 <span class="s2">&quot;cd /srv/ &amp;&amp; tar xzf tachyon-0.8.0-hadoop2.6-bin.tar.gz&quot;</span>
</code></pre></div>

<p>On both mesos-master-1 and mesos-slave-1, copy /srv/tachyon-0.8.0/conf/tachyon-env.sh.swift
to /srv/tachyon-0.8.0/conf/tachyon-env.sh</p>
<div class="highlight"><pre><span></span><code>mv /srv/tachyon-0.8.0/conf/tachyon-env.sh<span class="o">{</span>.swift,<span class="o">}</span>
</code></pre></div>

<p>Make minor modifications to /srv/tachyon-0.8.0/conf/tachyon-env.sh on both mesos-master-1 and
mesos-slave-1:</p>
<div class="highlight"><pre><span></span><code><span class="nb">export</span> <span class="nv">TACHYON_MASTER_ADDRESS</span><span class="o">=</span><span class="m">192</span>.168.111.54
<span class="nb">export</span> <span class="nv">TACHYON_UNDERFS_ADDRESS</span><span class="o">=</span>swift://spark.swift1
</code></pre></div>

<p>The TACHYON_MASTER_ADDRESS is set to the use the external IP
of the mesos-master node. The variable TACHYON_UNDERFS_ADDRESS
is set to swift://spark.swift1 where spark is the name of the
Swift container and swift1 is an arbitary name to specify
an Swift connection object defined in tachyon/conf/core-site.xml.</p>
<p>Now in core-site.xml we need to define how to connect to Swift.
This is done by changing settings for swift1 provider in
core-site.xml. I'm using Keystone
to authenticate with Swift and also to retreive the
correct endpoint.</p>
<p>I've changed core-site.xml according to my Swift environment and
copied it to tachyon/conf/core-site.xml. The following changes were made:</p>
<div class="highlight"><pre><span></span><code>&lt;property&gt;
 &lt;name&gt;fs.swift.service.swift1.location-aware&lt;/name&gt;
 &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.swift.service.swift1.auth.url&lt;/name&gt;
  &lt;value&gt;http://10.10.10.10:5000/v2.0/tokens&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.swift.service.swift1.http.port&lt;/name&gt;
  &lt;value&gt;8080&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.swift.service.swift1.region&lt;/name&gt;
  &lt;value&gt;RegionOne&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.swift.service.swift1.public&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.swift.service.swift1.auth.endpoint.prefix&lt;/name&gt;
  &lt;value&gt;endpoints&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.swift.service.swift1.tenant&lt;/name&gt;
  &lt;value&gt;spark&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.swift.service.swift1.password&lt;/name&gt;
  &lt;value&gt;test123&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;fs.swift.service.swift1.username&lt;/name&gt;
  &lt;value&gt;spark&lt;/value&gt;
&lt;/property&gt;
</code></pre></div>

<p>After all config changes are done we can start launching
the Tachyon master process on the mesos-master-1 node.</p>
<div class="highlight"><pre><span></span><code>/srv/tachyon-0.8.0/bin/tachyon-start.sh master -f
</code></pre></div>

<p>After successful start of the tachyon master, also start the tachyon worker
on mesos-slave-1:</p>
<div class="highlight"><pre><span></span><code>/srv/tachyon-0.8.0/bin/tachyon-start.sh worker SudoMount
</code></pre></div>

<p>You should now have Tachyon running and you can access it via
http://192.168.111.54:19999</p>
<h2>Building Spark with Tachyon 0.8.0 and Swift</h2>
<p>Checkout latest master branch of spark:</p>
<div class="highlight"><pre><span></span><code>git clone https://github.com/apache/spark.git
</code></pre></div>

<p>Apply the following patches to core/pom.xml and make_distribution.sh
to use tachyon 0.8.0 and to include hdfs as underfs dependency.
Make sure to exclude mockito-all else the build will fail with</p>
<div class="highlight"><pre><span></span><code><span class="gh">diff --git a/core/pom.xml b/core/pom.xml</span><span class="w"></span>
<span class="gh">index 570a25c..98285a0 100644</span><span class="w"></span>
<span class="gd">--- a/core/pom.xml</span><span class="w"></span>
<span class="gi">+++ b/core/pom.xml</span><span class="w"></span>
<span class="gu">@@ -262,7 +262,7 @@</span><span class="w"></span>
<span class="w"> </span>    &lt;dependency&gt;<span class="w"></span>
<span class="w"> </span>      &lt;groupId&gt;org.tachyonproject&lt;/groupId&gt;<span class="w"></span>
<span class="w"> </span>      &lt;artifactId&gt;tachyon-client&lt;/artifactId&gt;<span class="w"></span>
<span class="gd">-      &lt;version&gt;0.8.1&lt;/version&gt;</span><span class="w"></span>
<span class="gi">+      &lt;version&gt;0.8.0&lt;/version&gt;</span><span class="w"></span>
<span class="w"> </span>      &lt;exclusions&gt;<span class="w"></span>
<span class="w"> </span>        &lt;exclusion&gt;<span class="w"></span>
<span class="w"> </span>          &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;<span class="w"></span>
<span class="gu">@@ -287,6 +287,17 @@</span><span class="w"></span>
<span class="w"> </span>      &lt;/exclusions&gt;<span class="w"></span>
<span class="w"> </span>    &lt;/dependency&gt;<span class="w"></span>
<span class="w"> </span>    &lt;dependency&gt;<span class="w"></span>
<span class="gi">+      &lt;groupId&gt;org.tachyonproject&lt;/groupId&gt;</span><span class="w"></span>
<span class="gi">+      &lt;artifactId&gt;tachyon-underfs-swift&lt;/artifactId&gt;</span><span class="w"></span>
<span class="gi">+      &lt;version&gt;0.8.0&lt;/version&gt;</span><span class="w"></span>
<span class="gi">+      &lt;exclusions&gt;</span><span class="w"></span>
<span class="gi">+        &lt;exclusion&gt;</span><span class="w"></span>
<span class="gi">+          &lt;groupId&gt;org.mockito&lt;/groupId&gt;</span><span class="w"></span>
<span class="gi">+          &lt;artifactId&gt;mockito-all&lt;/artifactId&gt;</span><span class="w"></span>
<span class="gi">+        &lt;/exclusion&gt;</span><span class="w"></span>
<span class="gi">+      &lt;/exclusions&gt;</span><span class="w"></span>
<span class="gi">+    &lt;/dependency&gt;</span><span class="w"></span>
<span class="gi">+    &lt;dependency&gt;</span><span class="w"></span>
<span class="w"> </span>      &lt;groupId&gt;org.seleniumhq.selenium&lt;/groupId&gt;<span class="w"></span>
<span class="w"> </span>      &lt;artifactId&gt;selenium-java&lt;/artifactId&gt;<span class="w"></span>
<span class="w"> </span>      &lt;exclusions&gt;<span class="w"></span>

<span class="gh">diff --git a/make-distribution.sh b/make-distribution.sh</span><span class="w"></span>
<span class="gh">index e1c2afd..f676678 100755</span><span class="w"></span>
<span class="gd">--- a/make-distribution.sh</span><span class="w"></span>
<span class="gi">+++ b/make-distribution.sh</span><span class="w"></span>
<span class="gu">@@ -33,7 +33,7 @@ SPARK_HOME=&quot;$(cd &quot;`dirname &quot;$0&quot;`&quot;; pwd)&quot;</span><span class="w"></span>
<span class="w"> </span>DISTDIR=&quot;$SPARK_HOME/dist&quot;<span class="w"></span>

<span class="w"> </span>SPARK_TACHYON=false<span class="w"></span>
<span class="gd">-TACHYON_VERSION=&quot;0.8.1&quot;</span><span class="w"></span>
<span class="gi">+TACHYON_VERSION=&quot;0.8.0&quot;</span><span class="w"></span>
<span class="w"> </span>TACHYON_TGZ=&quot;tachyon-${TACHYON_VERSION}-bin.tar.gz&quot;<span class="w"></span>
<span class="w"> </span>TACHYON_URL=&quot;http://tachyon-project.org/downloads/files/${TACHYON_VERSION}/${TACHYON_TGZ}&quot;<span class="w"></span>
</code></pre></div>

<p>Build Spark with Tachyon and Swift as underfs:</p>
<div class="highlight"><pre><span></span><code>./make-distribution.sh --name spark-master-tachyon-0.8.0 --tgz --with-tachyon -Pyarn -Phadoop-2.6 -Dhadoop.version<span class="o">=</span><span class="m">2</span>.6.0 -DskipTests
</code></pre></div>

<p>Add core-site.xml which we used in Tachyon to the Spark tarball. </p>
<div class="highlight"><pre><span></span><code>tar xzf spark-1.6.0-SNAPSHOT-bin-spark-master-tachyon-0.8.0.tgz
cp /srv/tachyon-0.8.0/conf/core-site.xml spark-1.6.0*/conf/core-site.xml
tar czf spark-1.6.0.tar.gz spark-1.6.0-SNAPSHOT-bin-spark-master-tachyon-0.8.0
</code></pre></div>

<p>For some reason Spark also needs core-site.xml with the Swift connection settings
even though we already configured this in Tachyon.</p>
<h2>Running a Spark job with Tachyon as input backed by Swift</h2>
<p>Assuming that in our Swift container we have an object called
output.log we can now create a Spark shell session and use</p>
<div class="highlight"><pre><span></span><code>spark-shell
val <span class="nv">textFile</span> <span class="o">=</span> sc.textFile<span class="o">(</span><span class="s2">&quot;tachyon://mesos-master-1:19998/output.log&quot;</span><span class="o">)</span>
textFile.count<span class="o">()</span>
</code></pre></div>

<p>I've also verified that I could successfuly use sequenceFiles and Spark pickleFiles on
Tachyon with Swift by running the Python spark jobs of my other project: 
<a href="https://github.com/samos123/computer-vision-cloud-platform">Spark Computer vision</a></p>
<div id="disqus_thread"></div>
<script type="text/javascript">
	var disqus_shortname = 'samosit';
	(function() {
		var d = document, s = d.createElement('script'); s.type = 'text/javascript'; s.async = true;
		s.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
		s.setAttribute('data-timestamp', +new Date());
		(d.head || d.body).appendChild(s);
	})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>
		</div>
	</body>
</html>