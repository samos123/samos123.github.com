<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns#">
	<head>
		<link href="http://gmpg.org/xfn/11" rel="profile">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta http-equiv="content-type" content="text/html; charset=utf-8">

		<!-- Metadata -->
    <title>GKE GPU timesharing and resource quotas experiment</title>
	<meta name="description" content="Open source contributor and Cloud Architect. Creator of websu.io and bgdestroyer.com">
	<meta property="og:description" content="Open source contributor and Cloud Architect. Creator of websu.io and bgdestroyer.com">
	<meta property="og:title" content="GKE GPU timesharing and resource quotas experiment" />
	<meta property="og:type" content="article" />
	<meta property="og:url" content="https://samos-it.com/posts/gke-gpu-timesharing-resource-quotas.html" />
		<meta property="og:image" content="https://samos-it.com/images/sam-young.jpg" />

		<!-- Enable responsiveness on mobile devices-->
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

		<title>Sam Stoelinga</title>

		<!-- CSS -->
		<link href="//fonts.googleapis.com/" rel="dns-prefetch">
		<link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic|Abril+Fatface|PT+Sans:400,400italic,700&amp;subset=latin,latin-ext" rel="stylesheet">

		<link rel="stylesheet" href="https://samos-it.com/theme/css/poole.css" />
		<link rel="stylesheet" href="https://samos-it.com/theme/css/hyde.css" />
		<link rel="stylesheet" href="https://samos-it.com/theme/css/syntax.css" />
			<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.1.7/css/fork-awesome.min.css" crossorigin="anonymous">

		<!-- Feeds -->
<link href="https://samos-it.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Sam Stoelinga Full Atom Feed" />
<link href="https://samos-it.com/feeds/k8s.atom.xml" type="application/atom+xml" rel="alternate" title="Sam Stoelinga Categories Atom Feed" />

		<!-- Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-20975967-1', 'auto');
ga('send', 'pageview');
</script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5428887338428046"
     crossorigin="anonymous"></script>
	</head>

	<body class="theme-base-0d">
<div class="sidebar">
	<div class="container sidebar-sticky">
		<div class="sidebar-about">

			<h1>
				<a href="/">
					<img class="profile-picture" src="https://samos-it.com/images/sam-young.jpg">
					Sam Stoelinga
				</a>
			</h1>
			<p class="lead"></p>
			<p class="lead">Open source contributor and Cloud Architect. Creator of websu.io and bgdestroyer.com </p>
			<p></p>
		</div>
			<ul class="sidebar-nav">
					<li><a href="https://samos-it.com/pages/about.html">About Me</a></li>
					<li><a href="https://samos-it.com/pages/hire-me.html">Hire Me</a></li>
			</ul>
		<nav class="sidebar-social">
					<a class="sidebar-social-item" href="https://www.linkedin.com/in/samstoelinga/" target="_blank">
						<i class="fa fa-linkedin"></i>
					</a>
					<a class="sidebar-social-item" href="http://github.com/samos123/" target="_blank">
						<i class="fa fa-github"></i>
					</a>
			<a class="sidebar-social-item" href="https://samos-it.com/feeds/all.atom.xml">
				<i class="fa fa-rss"></i>
			</a>
		</nav>
	</div>
</div>		<div class="content container">
<div class="post">
	<h1 class="post-title">GKE GPU timesharing and resource quotas experiment</h1>
	<span class="post-date">Fri 26 August 2022</span>
	<p>You only got a few GPUs and want to pretend to your end-users that you got
many? Then GKE GPU timesharing might just be the feature for you to save
costs on GPUs that are underutilized. In this
blog post you will learn:</p>
<ol>
<li>Creating a GKE nodepool with timesharing enabled</li>
<li>Configure GPU based ResourseQuotas on multiple namespaces</li>
<li>How it's possible to request 4 GPUs in different namespaces even though there is only a single physical GPU</li>
</ol>
<h2>Creating the cluster and nodepool</h2>
<p>Create a cluster that meets the requirements of timesharing. At the time of
writing the blog post this requires using the rapid release channel.
This creates a cluster with a default CPU only nodepool using e2-medium.
System services will run on the default CPU only nodepool.</p>
<div class="highlight"><pre><span></span><code><span class="n">gcloud</span><span class="w"> </span><span class="n">container</span><span class="w"> </span><span class="n">clusters</span><span class="w"> </span><span class="n">create</span><span class="w"> </span><span class="n">gpu</span><span class="o">-</span><span class="n">gpu</span><span class="o">-</span><span class="n">timesharing</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">  </span><span class="o">--</span><span class="n">region</span><span class="w"> </span><span class="n">us</span><span class="o">-</span><span class="n">central1</span><span class="w"> </span><span class="o">--</span><span class="n">node</span><span class="o">-</span><span class="n">locations</span><span class="o">=</span><span class="n">us</span><span class="o">-</span><span class="n">central1</span><span class="o">-</span><span class="n">a</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">  </span><span class="o">--</span><span class="n">machine</span><span class="o">-</span><span class="k">type</span><span class="w"> </span><span class="n">e2</span><span class="o">-</span><span class="k">medium</span><span class="w"> </span><span class="o">--</span><span class="n">max</span><span class="o">-</span><span class="n">nodes</span><span class="o">=</span><span class="mh">3</span><span class="w"> </span><span class="o">--</span><span class="n">min</span><span class="o">-</span><span class="n">nodes</span><span class="o">=</span><span class="mh">1</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">  </span><span class="o">--</span><span class="n">enable</span><span class="o">-</span><span class="n">autoscaling</span><span class="w"> </span><span class="o">--</span><span class="k">release</span><span class="o">-</span><span class="n">channel</span><span class="w"> </span><span class="n">rapid</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">  </span><span class="o">--</span><span class="n">shielded</span><span class="o">-</span><span class="n">integrity</span><span class="o">-</span><span class="n">monitoring</span><span class="w"> </span><span class="o">--</span><span class="n">shielded</span><span class="o">-</span><span class="n">secure</span><span class="o">-</span><span class="n">boot</span><span class="w"></span>
</code></pre></div>

<p>Create the T4 GPU nodepool with timesharing enabled</p>
<div class="highlight"><pre><span></span><code><span class="n">gcloud</span><span class="w"> </span><span class="n">container</span><span class="w"> </span><span class="n">node</span><span class="o">-</span><span class="n">pools</span><span class="w"> </span><span class="n">create</span><span class="w"> </span><span class="n">gpu</span><span class="o">-</span><span class="kt">time</span><span class="o">-</span><span class="n">sharing</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">    </span><span class="o">--</span><span class="n">cluster</span><span class="o">=</span><span class="n">gke</span><span class="o">-</span><span class="n">gpu</span><span class="o">-</span><span class="n">timesharing</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">    </span><span class="o">--</span><span class="n">machine</span><span class="o">-</span><span class="k">type</span><span class="o">=</span><span class="n">n1</span><span class="o">-</span><span class="n">standard</span><span class="o">-</span><span class="mh">4</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">    </span><span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">nodes</span><span class="o">=</span><span class="mh">1</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">    </span><span class="o">--</span><span class="n">region</span><span class="o">=</span><span class="n">us</span><span class="o">-</span><span class="n">central1</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">    </span><span class="o">--</span><span class="n">node</span><span class="o">-</span><span class="n">locations</span><span class="o">=</span><span class="n">us</span><span class="o">-</span><span class="n">central1</span><span class="o">-</span><span class="n">a</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">    </span><span class="o">--</span><span class="n">accelerator</span><span class="o">=</span><span class="k">type</span><span class="o">=</span><span class="n">nvidia</span><span class="o">-</span><span class="n">tesla</span><span class="o">-</span><span class="n">t4</span><span class="p">,</span><span class="n">count</span><span class="o">=</span><span class="mh">1</span><span class="p">,</span><span class="n">gpu</span><span class="o">-</span><span class="n">sharing</span><span class="o">-</span><span class="n">strategy</span><span class="o">=</span><span class="kt">time</span><span class="o">-</span><span class="n">sharing</span><span class="p">,</span><span class="n">max</span><span class="o">-</span><span class="n">shared</span><span class="o">-</span><span class="n">clients</span><span class="o">-</span><span class="n">per</span><span class="o">-</span><span class="n">gpu</span><span class="o">=</span><span class="mh">8</span><span class="w"> </span><span class="se">\</span><span class="w"></span>
<span class="w">    </span><span class="o">--</span><span class="n">shielded</span><span class="o">-</span><span class="n">secure</span><span class="o">-</span><span class="n">boot</span><span class="w"> </span><span class="o">--</span><span class="n">shielded</span><span class="o">-</span><span class="n">integrity</span><span class="o">-</span><span class="n">monitoring</span><span class="w"></span>
</code></pre></div>

<p>Install the nvidia GPU device drivers:</p>
<div class="highlight"><pre><span></span><code><span class="n">kubectl</span><span class="w"> </span><span class="n">apply</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="w"> </span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">GoogleCloudPlatform</span><span class="o">/</span><span class="n">container</span><span class="o">-</span><span class="n">engine</span><span class="o">-</span><span class="n">accelerators</span><span class="o">/</span><span class="k">master</span><span class="o">/</span><span class="n">nvidia</span><span class="o">-</span><span class="n">driver</span><span class="o">-</span><span class="n">installer</span><span class="o">/</span><span class="nb">cos</span><span class="o">/</span><span class="n">daemonset</span><span class="o">-</span><span class="n">preloaded</span><span class="o">-</span><span class="n">latest</span><span class="o">.</span><span class="n">yaml</span><span class="w"></span>
</code></pre></div>

<p>You should now have a working GKE cluster with 2 nodepools. A CPU only nodepool and a GPU nodepool with 1 GPU node that has 1 T4.
This T4 GPU can be used by up to 8 clients at the same time. So it could be used by 8 pods each
requesting 1 GPU or it could be used by 2 pods each requesting 4 GPUs.</p>
<h2>Creating  the namespaces and resource quotas</h2>
<p>The example will use 2 fictional tenants: tenant-a and tenant-b.</p>
<p>Create the namespaces for both tenants:</p>
<div class="highlight"><pre><span></span><code>kubectl create ns tenant-a
kubectl create ns tenant-b
</code></pre></div>

<p>Create a quota for tenant-a</p>
<div class="highlight"><pre><span></span><code>cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: v1
kind: ResourceQuota
metadata:
  name: test-gpu-quota-1
  namespace: tenant-a
spec:
  hard:
    requests.nvidia.com/gpu: 1
    limits.nvidia.com/gpu: 1
    requests.cpu: 1
    limits.cpu: 1
EOF
</code></pre></div>

<p>Create a quota for tenant-b</p>
<div class="highlight"><pre><span></span><code>cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: v1
kind: ResourceQuota
metadata:
  name: test-gpu-quota-1
  namespace: tenant-b
spec:
  hard:
    requests.nvidia.com/gpu: 10
    limits.nvidia.com/gpu: 10
    requests.cpu: 2
    limits.cpu: 2
EOF
</code></pre></div>

<h1>Creating a GPU pod in tenant-a and tenant-b</h1>
<p>Let's create 4 pods in tenant-a and 4 pods in tenant-b where each pod
is requesting a single GPU.</p>
<p>The job that we will use in both tenants.</p>
<div class="highlight"><pre><span></span><code><span class="nt">cat</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nt">gpu-deployment</span><span class="p">.</span><span class="nc">yml</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="nt">EOF</span><span class="w"></span>
<span class="nt">apiVersion</span><span class="o">:</span><span class="w"> </span><span class="nt">apps</span><span class="o">/</span><span class="nt">v1</span><span class="w"></span>
<span class="nt">kind</span><span class="o">:</span><span class="w"> </span><span class="nt">Deployment</span><span class="w"></span>
<span class="nt">metadata</span><span class="o">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="o">:</span><span class="w"> </span><span class="nt">cuda-simple</span><span class="w"></span>
<span class="nt">spec</span><span class="o">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">replicas</span><span class="o">:</span><span class="w"> </span><span class="nt">4</span><span class="w"></span>
<span class="w">  </span><span class="nt">selector</span><span class="o">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">matchLabels</span><span class="o">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">app</span><span class="o">:</span><span class="w"> </span><span class="nt">cuda-simple</span><span class="w"></span>
<span class="w">  </span><span class="nt">template</span><span class="o">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">metadata</span><span class="o">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">labels</span><span class="o">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">app</span><span class="o">:</span><span class="w"> </span><span class="nt">cuda-simple</span><span class="w"></span>
<span class="w">    </span><span class="nt">spec</span><span class="o">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">containers</span><span class="o">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">-</span><span class="w"> </span><span class="nt">name</span><span class="o">:</span><span class="w"> </span><span class="nt">cuda-simple</span><span class="w"></span>
<span class="w">        </span><span class="nt">image</span><span class="o">:</span><span class="w"> </span><span class="nt">nvidia</span><span class="o">/</span><span class="nt">cuda</span><span class="p">:</span><span class="nd">11</span><span class="p">.</span><span class="nc">0</span><span class="p">.</span><span class="nc">3-base-ubi7</span><span class="w"></span>
<span class="w">        </span><span class="nt">command</span><span class="o">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">-</span><span class="w"> </span><span class="nt">bash</span><span class="w"></span>
<span class="w">        </span><span class="nt">-</span><span class="w"> </span><span class="nt">-c</span><span class="w"></span>
<span class="w">        </span><span class="nt">-</span><span class="w"> </span><span class="o">|</span><span class="w"></span>
<span class="w">          </span><span class="o">/</span><span class="nt">usr</span><span class="o">/</span><span class="nt">local</span><span class="o">/</span><span class="nt">nvidia</span><span class="o">/</span><span class="nt">bin</span><span class="o">/</span><span class="nt">nvidia-smi</span><span class="w"> </span><span class="nt">-L</span><span class="o">;</span><span class="w"> </span><span class="nt">sleep</span><span class="w"> </span><span class="nt">300</span><span class="w"></span>
<span class="w">        </span><span class="nt">resources</span><span class="o">:</span><span class="w"></span>
<span class="w">          </span><span class="nt">limits</span><span class="o">:</span><span class="w"></span>
<span class="w">            </span><span class="nt">nvidia</span><span class="p">.</span><span class="nc">com</span><span class="o">/</span><span class="nt">gpu</span><span class="o">:</span><span class="w"> </span><span class="nt">1</span><span class="w"></span>
<span class="nt">EOF</span><span class="w"></span>
</code></pre></div>

<p>launch it in tenant-a and tenant-b</p>
<div class="highlight"><pre><span></span><code>kubectl apply -f gpu-deployment.yml -n tenant-a
kubectl apply -f gpu-deployment.yml -n tenant-b
</code></pre></div>

<p>You should see 1 pod running in tenant-a:</p>
<div class="highlight"><pre><span></span><code>kubectl get pods -n tenant-a
</code></pre></div>

<p>this demonstrates that resourcequotas are effective
and able to limit GPUs that are timeshared.</p>
<p>You should see 4 pods running in tenant-a:</p>
<div class="highlight"><pre><span></span><code>kubectl get pods -n tenant-b
</code></pre></div>

<p>Verify that pods in both tenant-a see the whole GPU being usable</p>
<div class="highlight"><pre><span></span><code><span class="nv">kubectl</span><span class="w"> </span><span class="k">exec</span><span class="w"> </span><span class="o">-</span><span class="nv">n</span><span class="w"> </span><span class="nv">tenant</span><span class="o">-</span><span class="nv">a</span><span class="w"> </span><span class="nv">deploy</span><span class="o">/</span><span class="nv">cuda</span><span class="o">-</span><span class="nv">simple</span><span class="w"> </span><span class="o">-</span><span class="nv">ti</span><span class="w"> </span><span class="o">--</span><span class="w"> </span><span class="nv">sh</span><span class="w"></span>
<span class="nv">nvidia</span><span class="o">-</span><span class="nv">smi</span><span class="w"></span>
<span class="k">exit</span><span class="w"></span>
</code></pre></div>

<p>Verify that pods in tenant-b  see the whole GPU being usable</p>
<div class="highlight"><pre><span></span><code><span class="nv">kubectl</span><span class="w"> </span><span class="k">exec</span><span class="w"> </span><span class="o">-</span><span class="nv">n</span><span class="w"> </span><span class="nv">tenant</span><span class="o">-</span><span class="nv">b</span><span class="w"> </span><span class="nv">deploy</span><span class="o">/</span><span class="nv">cuda</span><span class="o">-</span><span class="nv">simple</span><span class="w"> </span><span class="o">-</span><span class="nv">ti</span><span class="w"> </span><span class="o">--</span><span class="w"> </span><span class="nv">sh</span><span class="w"></span>
<span class="nv">nvidia</span><span class="o">-</span><span class="nv">smi</span><span class="w"></span>
<span class="k">exit</span><span class="w"></span>
</code></pre></div>

<p>You can also take a look at the GPU node to see that it will
report having 8 GPU devices even though it only has a single GPU
attached to the VM. This is due to the fact of timesharing being
enabled with the setting <code>max-shared-clients-per-gpu=8</code>. </p>
<p>Run the following to get node details of the GPU nodes with tesla t4s</p>
<div class="highlight"><pre><span></span><code>kubectl get node -l cloud.google.com/gke-accelerator=nvidia-tesla-t4 -o yaml
</code></pre></div>

<p>You should see something like this in the output:</p>
<div class="highlight"><pre><span></span><code>    allocatable:
      attachable-volumes-gce-pd: &quot;127&quot;
      cpu: 3920m
      ephemeral-storage: &quot;47093746742&quot;
      hugepages-1Gi: &quot;0&quot;
      hugepages-2Mi: &quot;0&quot;
      memory: 12663300Ki
      nvidia.com/gpu: &quot;1&quot;
      pods: &quot;110&quot;
</code></pre></div>

<h2>Summary</h2>
<p>Demonstrated how to use timesharing GPUs in GKE and verified that each tenant
will think they're getting the whole GPU even when they are being shared.
We are able to limit how much GPUs a single tenant can request by applying
resource quotas. GPU timesharing is a great way to reduce costs of GPUs when the
GPU utilization of a single tenant/user is low.</p>
<div id="disqus_thread"></div>
<script type="text/javascript">
	var disqus_shortname = 'samosit';
	(function() {
		var d = document, s = d.createElement('script'); s.type = 'text/javascript'; s.async = true;
		s.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
		s.setAttribute('data-timestamp', +new Date());
		(d.head || d.body).appendChild(s);
	})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>
		</div>
	</body>
</html>